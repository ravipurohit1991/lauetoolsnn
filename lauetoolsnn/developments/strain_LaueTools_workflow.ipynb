{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strain minimization of LaueTools\n",
    "### Useful for users to understand the strain minimization\n",
    "\n",
    "### pip install lauetoolsnn \n",
    "### use the above command to install lauetoolsnn to be able to use this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adjustText library not installed\n"
     ]
    }
   ],
   "source": [
    "## import required functions\n",
    "import numpy as np\n",
    "import os\n",
    "from lauetoolsnn.utils_lauenn import resource_path\n",
    "\n",
    "base_lib_path = resource_path('')\n",
    "import json\n",
    "## Load the json of material and extinctions\n",
    "with open(os.path.join(base_lib_path, 'lauetools/material.json'),'r') as f:\n",
    "    dict_Materials = json.load(f)\n",
    "## Modify the dictionary values to add new entries\n",
    "dict_Materials[\"Cu_test\"] = [\"Cu_test\", [5, 5, 5, 90, 90, 90], \"fcc\"]\n",
    "dict_Materials[\"Cu_test_strain\"] = [\"Cu_test_strain\", [5., 5.02, 4.98, 90.0+np.random.rand(), 90.0+np.random.rand(), 90.0+np.random.rand()], \"fcc\"]\n",
    "## dump the json back with new values\n",
    "with open(os.path.join(base_lib_path, 'lauetools/material.json'), 'w') as fp:\n",
    "    json.dump(dict_Materials, fp)\n",
    "    \n",
    "### AFTER THIS STEP, RESTART THE KERNAL TO TAKE THIS NEW MAT INTO EFFECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cu_test_strain', [5.0, 5.02, 4.98, 90.48570992919974, 90.35046242365307, 90.74507566406014], 'fcc']\n",
      "UBmatrix of fake strained exp laue pattern is: [1. 0. 0.] [ 0.                 0.999998476913288 -0.001745328365898] [0.                0.001745328365898 0.999998476913288]\n",
      "['Cu_test', [5, 5, 5, 90, 90, 90], 'fcc']\n",
      "UBmatrix of reference laue pattern is: [1. 0. 0.] [0. 1. 0.] [0. 0. 1.]\n",
      "\n",
      "We will start with the non strained Cu as initial (reference) material, it should be changed to match the values of Fake Exp Laue patterns, which has some strain\n"
     ]
    }
   ],
   "source": [
    "## load Lauetoolsnn Library\n",
    "import lauetoolsnn.lauetools.dict_LaueTools as dictLT\n",
    "import lauetoolsnn.lauetools.generaltools as GT\n",
    "import lauetoolsnn.lauetools.CrystalParameters as CP\n",
    "import lauetoolsnn.lauetools.lauecore as LT\n",
    "import lauetoolsnn.lauetools.LaueGeometry as Lgeo\n",
    "import lauetoolsnn.lauetools.readmccd as RMCCD\n",
    "import lauetoolsnn.lauetools.FitOrient as FitO\n",
    "import lauetoolsnn.lauetools.LaueGeometry as F2TC\n",
    "\n",
    "mat_exp = \"Cu_test_strain\" ## No longer cubic\n",
    "mat_sim = \"Cu_test\"  ## reference is Cubic\n",
    "## Lets create a fake strained Experimental laue pattern with Cu_test_strain material\n",
    "detectorparameters = [79.5, 950, 950, 0.342, 0.482]\n",
    "pixelsize = 0.0734\n",
    "\n",
    "######################### FAKE EXPERIMENTAL PATTERN  ######################################\n",
    "UBmatrix_exp = np.eye(3)\n",
    "## lets rotate the fake pattern matrix by few degrees\n",
    "rot_angX = np.deg2rad(0.1)\n",
    "rot_angY = np.deg2rad(0.0)\n",
    "rot_angZ = np.deg2rad(0.0)\n",
    "mat1 = np.array([[np.cos(rot_angY), 0, np.sin(rot_angY)], [0, 1, 0], [-np.sin(rot_angY), 0, np.cos(rot_angY)]])\n",
    "mat2 = np.array([[1, 0, 0], [0, np.cos(rot_angX), np.sin(rot_angX)], [0, np.sin(-rot_angX), np.cos(rot_angX)]])\n",
    "mat3 = np.array([[np.cos(rot_angZ), -np.sin(rot_angZ), 0], [np.sin(rot_angZ), np.cos(rot_angZ), 0], [0, 0, 1]])\n",
    "deltamat = np.dot(mat3, np.dot(mat2, mat1))\n",
    "UBmatrix_exp = np.dot(deltamat, UBmatrix_exp)\n",
    "grain = CP.Prepare_Grain(mat_exp, UBmatrix_exp)\n",
    "s_tth, s_chi, Miller_ind_exp, exp_posx, exp_posy, _ = LT.SimulateLaue_full_np(grain, 5, 22,\n",
    "                                                    detectorparameters,\n",
    "                                                    pixelsize=pixelsize,\n",
    "                                                    dim=(2018,2016),\n",
    "                                                    detectordiameter=pixelsize*2018*1.3,\n",
    "                                                    removeharmonics=1)\n",
    "\n",
    "######################### SIMULATED PATTERN  ######################################\n",
    "UBmatrix = np.eye(3)\n",
    "grain = CP.Prepare_Grain(mat_sim, UBmatrix)\n",
    "Twicetheta, Chi, Miller_ind, s_posx, s_posy, s_E = LT.SimulateLaue_full_np(grain, 5, 22,\n",
    "                                                                            detectorparameters,\n",
    "                                                                            pixelsize=pixelsize,\n",
    "                                                                            dim=(2018,2016),\n",
    "                                                                            detectordiameter=pixelsize*2018*1.3,\n",
    "                                                                            removeharmonics=1)\n",
    "\n",
    "## test if new material is added or not\n",
    "UBmatrix = np.round(UBmatrix,4)\n",
    "print(dictLT.dict_Materials[\"Cu_test_strain\"])\n",
    "print(\"UBmatrix of fake strained exp laue pattern is:\", UBmatrix_exp[:,0], UBmatrix_exp[:,1], UBmatrix_exp[:,2])\n",
    "print(dictLT.dict_Materials[\"Cu_test\"])\n",
    "print(\"UBmatrix of reference laue pattern is:\", UBmatrix[:,0], UBmatrix[:,1], UBmatrix[:,2])\n",
    "print()\n",
    "print(\"We will start with the non strained Cu as initial (reference) material, it should be changed to match the values of Fake Exp Laue patterns, which has some strain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exp Sim\n",
      "109.88505944385517 109.47122063449068\n",
      "-44.42601204966866 -45.0\n",
      "2019.5034999558425 2040.9533820086704\n",
      "402.2656549906868 409.499614321252\n",
      "[-4 -2  2] [-4 -2  2]\n"
     ]
    }
   ],
   "source": [
    "### print how far both laue patterns are from each other in angle and pixel space\n",
    "print(\"Exp\", \"Sim\")\n",
    "print(s_tth[0], Twicetheta[0])\n",
    "print(s_chi[0], Chi[0])\n",
    "print(exp_posx[0], s_posx[0])\n",
    "print(exp_posy[0], s_posy[0])\n",
    "print(Miller_ind_exp[0], Miller_ind[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions used for strain computation by varying lattice parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Different functions\n",
    "def getProximity(TwicethetaChi, data_theta, data_chi, data_hkl, angtol=0.5):\n",
    "    \"\"\"This functions gives the indices of all the experimetnal spots that are close to the simulated spots\"\"\"\n",
    "    # theo simul data\n",
    "    theodata = np.array([TwicethetaChi[0] / 2.0, TwicethetaChi[1]]).T\n",
    "    # exp data\n",
    "    sorted_data = np.array([data_theta, data_chi]).T\n",
    "    table_dist = GT.calculdist_from_thetachi(sorted_data, theodata)\n",
    "    prox_table = np.argmin(table_dist, axis=1)\n",
    "    allresidues = np.amin(table_dist, axis=1)\n",
    "    very_close_ind = np.where(allresidues < angtol)[0]\n",
    "    List_Exp_spot_close = []\n",
    "    Miller_Exp_spot = []\n",
    "    if len(very_close_ind) > 0:\n",
    "        for theospot_ind in very_close_ind:  # loop over theo spots index\n",
    "            List_Exp_spot_close.append(prox_table[theospot_ind])\n",
    "            Miller_Exp_spot.append(data_hkl[theospot_ind])\n",
    "    else:\n",
    "        return [],[],[]\n",
    "    # removing exp spot which appears many times(close to several simulated spots of one grain)--------------\n",
    "    arrayLESC = np.array(List_Exp_spot_close, dtype=float)\n",
    "    sorted_LESC = np.sort(arrayLESC)\n",
    "    diff_index = sorted_LESC - np.array(list(sorted_LESC[1:]) + [sorted_LESC[0]])\n",
    "    toremoveindex = np.where(diff_index == 0)[0]\n",
    "    if len(toremoveindex) > 0:\n",
    "        # index of exp spot in arrayLESC that are duplicated\n",
    "        ambiguous_exp_ind = GT.find_closest(np.array(sorted_LESC[toremoveindex], dtype=float), arrayLESC, 0.1)[1]\n",
    "        for ind in ambiguous_exp_ind:\n",
    "            Miller_Exp_spot[ind] = None\n",
    "    ProxTablecopy = np.copy(prox_table)\n",
    "    for theo_ind, exp_ind in enumerate(prox_table):\n",
    "        where_th_ind = np.where(ProxTablecopy == exp_ind)[0]\n",
    "        if len(where_th_ind) > 1:\n",
    "            for indy in where_th_ind:\n",
    "                ProxTablecopy[indy] = -prox_table[indy]\n",
    "            closest = np.argmin(allresidues[where_th_ind])\n",
    "            ProxTablecopy[where_th_ind[closest]] = -ProxTablecopy[where_th_ind[closest]]\n",
    "    singleindices = []\n",
    "    refine_indexed_spots = {}\n",
    "    # loop over close exp. spots\n",
    "    for k in range(len(List_Exp_spot_close)):\n",
    "        exp_index = List_Exp_spot_close[k]\n",
    "        if not singleindices.count(exp_index):\n",
    "            singleindices.append(exp_index)\n",
    "            theo_index = np.where(ProxTablecopy == exp_index)[0]\n",
    "            if (len(theo_index) == 1):  # only one theo spot close to the current exp. spot\n",
    "                refine_indexed_spots[exp_index] = [exp_index, theo_index, Miller_Exp_spot[k]]\n",
    "            else:  # recent PATCH:\n",
    "                closest_theo_ind = np.argmin(allresidues[theo_index])\n",
    "                if allresidues[theo_index][closest_theo_ind] < angtol:\n",
    "                    refine_indexed_spots[exp_index] = [exp_index, theo_index[closest_theo_ind], Miller_Exp_spot[k]]\n",
    "    listofpairs = []\n",
    "    linkExpMiller = []\n",
    "    selectedAbsoluteSpotIndices = np.arange(len(data_theta))\n",
    "    for val in list(refine_indexed_spots.values()):\n",
    "        if val[2] is not None:\n",
    "            localspotindex = val[0]\n",
    "            if not isinstance(val[1], (list, np.ndarray)):\n",
    "                closetheoindex = val[1]\n",
    "            else:\n",
    "                closetheoindex = val[1][0]\n",
    "            absolute_spot_index = selectedAbsoluteSpotIndices[localspotindex]\n",
    "            listofpairs.append([absolute_spot_index, closetheoindex])  # Exp, Theo,  where -1 for specifying that it came from automatic linking\n",
    "            linkExpMiller.append([float(absolute_spot_index)] + [float(elem) for elem in val[2]])  # float(val) for further handling as floats array\n",
    "    linkedspots_link = np.array(listofpairs)\n",
    "    linkExpMiller_link = linkExpMiller\n",
    "    return linkedspots_link, linkExpMiller_link\n",
    "\n",
    "def error_function_on_demand_strain(param_strain, DATA_Q, nspots,\n",
    "                                    pixX, pixY, initrot=np.eye(3), Bmat=np.eye(3),\n",
    "                                    verbose=0, pixelsize=165.0 / 2048., weights=None,\n",
    "                                    kf_direction=\"Z>0\"):\n",
    "    DEG = np.pi / 180.0\n",
    "    RAD = 1.0 / DEG\n",
    "    ## Building rotation matrix along X, Y and Z\n",
    "    a1 = param_strain[5] * DEG\n",
    "    mat1 = np.array([[np.cos(a1), 0, np.sin(a1)], [0, 1, 0], [-np.sin(a1), 0, np.cos(a1)]])\n",
    "    a2 = param_strain[6] * DEG\n",
    "    mat2 = np.array([[1, 0, 0], [0, np.cos(a2), np.sin(a2)], [0, np.sin(-a2), np.cos(a2)]])\n",
    "    a3 = param_strain[7] * DEG\n",
    "    mat3 = np.array([[np.cos(a3), -np.sin(a3), 0], [np.sin(a3), np.cos(a3), 0], [0, 0, 1]])\n",
    "    deltamat = np.dot(mat3, np.dot(mat2, mat1))\n",
    "\n",
    "    # building B mat with proposed lattice parameters (except 'a' is fixed to 1)\n",
    "    varyingstrain = np.array([[1.0, param_strain[2], param_strain[3]], [0, param_strain[0], param_strain[4]],  [0, 0, param_strain[1]]])\n",
    "    newmatrix = np.dot(np.dot(deltamat, initrot), varyingstrain)\n",
    "    \n",
    "    X, Y, _, _ = xy_from_Quat(DATA_Q, nspots,\n",
    "                                initrot=newmatrix, vecteurref=Bmat,\n",
    "                                pixelsize=pixelsize, kf_direction=kf_direction)\n",
    "    distanceterm = np.sqrt((X - pixX) ** 2 + (Y - pixY) ** 2)\n",
    "    if weights is not None:\n",
    "        allweights = np.sum(weights)\n",
    "        distanceterm = distanceterm * weights / allweights\n",
    "    if verbose:\n",
    "        return distanceterm, deltamat, newmatrix\n",
    "    else:\n",
    "        print(\"SSE:\", np.sum(distanceterm))\n",
    "        return distanceterm\n",
    "    \n",
    "def xy_from_Quat(DATA_Q, nspots, initrot=None,  vecteurref=np.eye(3),\n",
    "                 pixelsize=165.0 / 2048, kf_direction=\"Z>0\"):\n",
    "    \"\"\"\n",
    "    compute x and y pixel positions of Laue spots given hkl list\n",
    "    \"\"\"\n",
    "    # selecting nspots of DATA_Q\n",
    "    DATAQ = np.take(DATA_Q, nspots, axis=0)\n",
    "    trQ = np.transpose(DATAQ)  # np.array(Hs, Ks, Ls) for further computations\n",
    "    # R is a pure rotation\n",
    "    # dot(R,Q)=initrot # Q may be viewed as lattice distortion\n",
    "    R = initrot # keep UB matrix rotation + distorsion\n",
    "    # initial lattice rotation and distorsion (/ cubic structure)  q = U*B * Q\n",
    "    trQ = np.dot(np.dot(R, vecteurref), trQ)\n",
    "    # results are qx,qy,qz\n",
    "    matfromQuat = np.eye(3)\n",
    "    Qrot = np.dot(matfromQuat, trQ)  # lattice rotation due to quaternion\n",
    "    Qrotn = np.sqrt(np.sum(Qrot ** 2, axis=0))  # norms of Q vectors\n",
    "    twthe, chi = F2TC.from_qunit_to_twchi(1.*Qrot / Qrotn)\n",
    "    X, Y, theta = F2TC.calc_xycam_from2thetachi(twthe, chi, detectorparameters, verbose=0, pixelsize=pixelsize, kf_direction=kf_direction)\n",
    "    return X, Y, theta, R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least square optimization to refine the lattice parameters (+ orientation) to match the experimental pattern\n",
    "\n",
    "#### Least square varies the Lattice parameters and we compute the new Laue pattern for the new lattice parameters\n",
    "#### Then the radial distance between the newly computed Laue spots and Experimental spots is used as minimization during least square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSE: 1387.9989853831157\n",
      "SSE: 1387.9989853831157\n",
      "SSE: 1387.9989853831157\n",
      "SSE: 1387.9991513925247\n",
      "SSE: 1387.9980616398552\n",
      "SSE: 1387.998779281717\n",
      "SSE: 1387.998554934979\n",
      "SSE: 1387.9979049817048\n",
      "SSE: 1387.998948598271\n",
      "SSE: 1387.998966590009\n",
      "SSE: 1387.9990214438637\n",
      "SSE: 18.063939173922105\n",
      "SSE: 18.064250604526627\n",
      "SSE: 18.06259538727565\n",
      "SSE: 18.063940997755303\n",
      "SSE: 18.063935236776352\n",
      "SSE: 18.06394315041869\n",
      "SSE: 18.063938932439594\n",
      "SSE: 18.063939706997054\n",
      "SSE: 18.06393916161224\n",
      "SSE: 0.009817796637352917\n",
      "SSE: 0.009992396345852403\n",
      "SSE: 0.008295673288872499\n",
      "SSE: 0.009817884411561718\n",
      "SSE: 0.009812674604501604\n",
      "SSE: 0.009815546634911496\n",
      "SSE: 0.009817796390304466\n",
      "SSE: 0.009817200658666196\n",
      "SSE: 0.009817796660076105\n",
      "SSE: 0.0018603135106324562\n",
      "SSE: 0.0016740052726688568\n",
      "SSE: 0.0026629740681045457\n",
      "SSE: 0.0018619964431318904\n",
      "SSE: 0.001859151312830089\n",
      "SSE: 0.0018607223787049218\n",
      "SSE: 0.0018603135124416095\n",
      "SSE: 0.0018601975170449254\n",
      "SSE: 0.0018603135149770742\n",
      "SSE: 0.0037499751243041625\n",
      "SSE: 0.0037499751243041625\n",
      "SSE: 0.0020956283689058043\n",
      "SSE: 0.0021979649272546495\n",
      "SSE: 0.001621127692363458\n",
      "SSE: 0.0020963064799473276\n",
      "SSE: 0.0020918923764448767\n",
      "SSE: 0.0020954894481174193\n",
      "SSE: 0.0020956282425871053\n",
      "SSE: 0.002095464252017059\n",
      "SSE: 0.0020956283805115645\n",
      "SSE: 0.001589524743249045\n",
      "SSE: 0.0016885016010462317\n",
      "SSE: 0.002074276801472659\n",
      "SSE: 0.001590390260783614\n",
      "SSE: 0.0015876361994393014\n",
      "SSE: 0.001591563534026994\n",
      "SSE: 0.0015895246923529483\n",
      "SSE: 0.0015899376290673644\n",
      "SSE: 0.0015895247351878608\n",
      "SSE: 0.0019432952960149366\n",
      "SSE: 0.0016743994121360102\n",
      "SSE: 0.0016171482516464126\n",
      "SSE: 0.0017430276321428332\n",
      "SSE: 0.0019226280084152316\n",
      "SSE: 0.0016180552862311058\n",
      "SSE: 0.001615010720683807\n",
      "SSE: 0.0016182259934232517\n",
      "SSE: 0.0016171481824516867\n",
      "SSE: 0.0016172718201552972\n",
      "SSE: 0.0016171482548210754\n",
      "SSE: 0.0016102135306230966\n",
      "SSE: 0.001738570783531627\n",
      "SSE: 0.0019214322947619274\n",
      "SSE: 0.0016111238837770866\n",
      "SSE: 0.0016081113772698744\n",
      "SSE: 0.0016112583460995218\n",
      "SSE: 0.001610213459090714\n",
      "SSE: 0.001610322668719674\n",
      "SSE: 0.0016102135323668204\n",
      "SSE: 0.001606853226633972\n",
      "SSE: 0.001735755807217093\n",
      "SSE: 0.001921201689973615\n",
      "SSE: 0.0016077620297132718\n",
      "SSE: 0.0016047667050515333\n",
      "SSE: 0.0016078972379198664\n",
      "SSE: 0.0016068531542957987\n",
      "SSE: 0.0016069602828748296\n",
      "SSE: 0.0016068532284963717\n",
      "SSE: 0.0016049893239936002\n",
      "SSE: 0.0017341394562441668\n",
      "SSE: 0.0019215859622583433\n",
      "SSE: 0.0016058957547496135\n",
      "SSE: 0.0016029117760190466\n",
      "SSE: 0.0016060344349997145\n",
      "SSE: 0.0016049892476290247\n",
      "SSE: 0.001605096068323545\n",
      "SSE: 0.0016049893204458734\n",
      "SSE: 0.0016038864913688116\n",
      "SSE: 0.001733855189505033\n",
      "SSE: 0.0019221751108451572\n",
      "SSE: 0.001604785987538387\n",
      "SSE: 0.0016018160721270702\n",
      "SSE: 0.0016049154439367276\n",
      "SSE: 0.0016038864246258643\n",
      "SSE: 0.0016039894509535736\n",
      "SSE: 0.00160388648768096\n",
      "SSE: 0.001603571832601795\n",
      "SSE: 0.0017337736668396144\n",
      "SSE: 0.001921938697457532\n",
      "SSE: 0.0016044693776471309\n",
      "SSE: 0.0016015030361312146\n",
      "SSE: 0.001604596029419869\n",
      "SSE: 0.0016035717617958667\n",
      "SSE: 0.0016036735457283552\n",
      "SSE: 0.00160357183797954\n",
      "SSE: 0.0016033748976292898\n",
      "SSE: 0.0017335191376717267\n",
      "SSE: 0.0019219378400399175\n",
      "SSE: 0.0016042726727938962\n",
      "SSE: 0.0016013068353177037\n",
      "SSE: 0.001604401271408604\n",
      "SSE: 0.001603374827729208\n",
      "SSE: 0.0016034770536742017\n",
      "SSE: 0.0016033748945114587\n",
      "SSE: 0.0016032372054294029\n",
      "Lattice values from Least square (without scaling) [0.995948095691134 1.003911487183115 0.013004474776718 0.006252480077157\n",
      " 0.008510665804363]\n",
      "Orientation values from Least square [3.673234874088115e-06 1.000002483329707e-01 2.244305657773474e-06]\n",
      "Deviatoric Strain (%) [ 0.048 -0.653 -0.305] [-0.653  0.44  -0.426] [-0.305 -0.426 -0.488]\n",
      "Reference Lattice [5, 5, 5, 90, 90, 90]\n",
      "Expected Lattice distortion [ 5.      5.02    4.98   90.4857 90.3505 90.7451]\n",
      "Strain refined Lattice from reference [ 5.      5.02    4.98   90.4857 90.3505 90.7451]\n",
      "Initial residues 17.349987317288946\n",
      "Final residues 2.0040465067867536e-05\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import leastsq\n",
    "\n",
    "## best guess UB matrix\n",
    "UBmat = UBmatrix #np.eye(3)\n",
    "\n",
    "## reference pattern\n",
    "lattice_params_sim = dictLT.dict_Materials[mat_sim][1]\n",
    "B0matrix = CP.calc_B_RR(lattice_params_sim)\n",
    "\n",
    "## get proximity for exp and theo spots\n",
    "linkedspots_link, linkExpMiller_link = getProximity(np.array([Twicetheta, Chi]),  # warning array(2theta, chi) ## Simulated\n",
    "                                                    s_tth/2.0, s_chi, # warning theta, chi for exp\n",
    "                                                    Miller_ind, angtol=0.5)\n",
    "\n",
    "if len(linkedspots_link) < 8:\n",
    "    print(\"Not enough spots to use Least square fitting\")\n",
    "else:\n",
    "    arraycouples = np.array(linkedspots_link)\n",
    "    exp_indices = np.array(arraycouples[:, 0], dtype=np.int)\n",
    "    sim_indices = np.array(arraycouples[:, 1], dtype=np.int)\n",
    "\n",
    "    nb_pairs = len(exp_indices)\n",
    "    Data_Q = np.array(linkExpMiller_link)[:, 1:]\n",
    "    sim_indices = np.arange(nb_pairs)  # for fitting function this must be an arange...\n",
    "\n",
    "    pixX = np.take(exp_posx, exp_indices)\n",
    "    pixY = np.take(exp_posy, exp_indices)\n",
    "\n",
    "    starting_orientmatrix = np.copy(UBmat)\n",
    "    # ----------------------------------\n",
    "    #  refinement model\n",
    "    # ----------------------------------\n",
    "    # -------------------------------------------------------\n",
    "    # strain & orient\n",
    "    initial_values = np.array([1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
    "    \n",
    "    residues, deltamat, newmatrix = error_function_on_demand_strain(\n",
    "                                                                    initial_values,\n",
    "                                                                    Data_Q,\n",
    "                                                                    sim_indices,\n",
    "                                                                    pixX,\n",
    "                                                                    pixY,\n",
    "                                                                    initrot=starting_orientmatrix,\n",
    "                                                                    Bmat=B0matrix,\n",
    "                                                                    verbose=1,\n",
    "                                                                    pixelsize=pixelsize,\n",
    "                                                                    weights=None,\n",
    "                                                                    kf_direction='Z>0')\n",
    "    init_mean_residues = np.copy(np.mean(residues))\n",
    "\n",
    "    # setting  keywords of error_function_on_demand_strain during the fitting because leastsq handle only *args but not **kwds\n",
    "    error_function_on_demand_strain.__defaults__ = (starting_orientmatrix,\n",
    "                                                    B0matrix,\n",
    "                                                    0,\n",
    "                                                    pixelsize,\n",
    "                                                    None,\n",
    "                                                    'Z>0')\n",
    "    # LEASTSQUARE\n",
    "    res = leastsq(error_function_on_demand_strain,\n",
    "                    initial_values,\n",
    "                    args=(Data_Q, sim_indices, pixX, pixY),\n",
    "                    maxfev=5000,\n",
    "                    full_output=1,\n",
    "                    xtol=1.0e-11,\n",
    "                    epsfcn=0.0)\n",
    "    strain_sol = res[0]\n",
    "    if res[-1] not in (1, 2, 3, 4, 5):\n",
    "        results = None\n",
    "        print(\"Results are None, no strain refinement done\")\n",
    "    else:\n",
    "        results = strain_sol\n",
    "    lattice_part = results[:5]\n",
    "    orient_part = results[5:]\n",
    "    residues, deltamat, newmatrix = error_function_on_demand_strain(\n",
    "                                                                    results,\n",
    "                                                                    Data_Q,\n",
    "                                                                    sim_indices,\n",
    "                                                                    pixX,\n",
    "                                                                    pixY,\n",
    "                                                                    initrot=starting_orientmatrix,\n",
    "                                                                    Bmat=B0matrix,\n",
    "                                                                    verbose=1,\n",
    "                                                                    pixelsize=pixelsize,\n",
    "                                                                    weights=None,\n",
    "                                                                    kf_direction='Z>0')\n",
    "    final_residues = np.copy(np.mean(residues))\n",
    "    UBmat = np.copy(newmatrix) \n",
    "    # ---------------------------------------------------------------\n",
    "    # postprocessing of unit cell orientation and strain refinement\n",
    "    # ---------------------------------------------------------------\n",
    "    \n",
    "    (devstrain, _) = CP.compute_deviatoricstrain(UBmat, B0matrix, lattice_params_sim)\n",
    "    # overwrite and rescale possibly lattice lengthes\n",
    "    constantlength = \"a\"\n",
    "    lattice_parameter_direct_strain = CP.computeLatticeParameters_from_UB(UBmat, mat_sim, constantlength, dictmaterials=dictLT.dict_Materials)\n",
    "    deviatoricstrain_sampleframe = CP.strain_from_crystal_to_sample_frame2(devstrain, UBmat)\n",
    "    # in % already\n",
    "    devstrain = np.round(devstrain * 100, decimals=3)\n",
    "    deviatoricstrain_sampleframe = np.round(deviatoricstrain_sampleframe * 100, decimals=3)\n",
    "    print(\"Lattice values from Least square (without scaling)\", lattice_part)\n",
    "    print(\"Orientation values from Least square\", orient_part)\n",
    "    print(\"Deviatoric Strain (%)\", devstrain[0,:], devstrain[1,:], devstrain[2,:])\n",
    "    print(\"Reference Lattice\", dictLT.dict_Materials[\"Cu_test\"][1])\n",
    "    print(\"Expected Lattice distortion\", np.round(dictLT.dict_Materials[\"Cu_test_strain\"][1],4))\n",
    "    print(\"Strain refined Lattice from reference\", np.round(lattice_parameter_direct_strain,4))\n",
    "    print(\"Initial residues\", init_mean_residues)\n",
    "    print(\"Final residues\", final_residues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lauenn",
   "language": "python",
   "name": "lauenn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
