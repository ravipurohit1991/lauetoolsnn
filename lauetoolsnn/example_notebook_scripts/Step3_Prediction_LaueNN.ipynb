{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1af0da07-df7c-4739-b772-d45d7ec8f03b",
   "metadata": {},
   "source": [
    "# Notebook script for Prediction of Laue spot hkl using the Trained model from step 2 (supports single and two phase material)\n",
    "# This notebook also includes complete indexation process from the predicted spot hkl\n",
    "\n",
    "## Different steps of loading model to predicting the hkl of spots is outlined in this notebook (LaueToolsNN GUI does the same thing)\n",
    "\n",
    "### Define material of interest and path to experimental data; the path to trained model will be extracted automatically by default\n",
    "### Load the trained model \n",
    "### Prediction of Laue spots hkl \n",
    "### Constructing orientation matrix from the predicted hkl (i.e. index Laue Patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2dc3970-18c2-4687-bcfc-36c2426c81f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Screen: \\\\.\\DISPLAY1\n",
      "Size: 1920 x 1080\n",
      "Available: 1920 x 1040\n",
      "Nothing to close\n",
      "Number of CPUs available :  16\n"
     ]
    }
   ],
   "source": [
    "## Import modules used for this Notebook\n",
    "import numpy as np\n",
    "import os\n",
    "import multiprocessing \n",
    "from multiprocessing import cpu_count\n",
    "import time, datetime\n",
    "import glob, re\n",
    "## if LaueToolsNN is properly installed\n",
    "try:\n",
    "    from lauetoolsnn.utils_lauenn import get_material_detail, read_hdf5, new_MP_function, global_plots\n",
    "    from lauetoolsnn.lauetools import dict_LaueTools as dictLT\n",
    "except:\n",
    "    # else import from a path where LaueToolsNN files are\n",
    "    import sys\n",
    "    sys.path.append(r\"C:\\Users\\purushot\\Desktop\\github_version_simple\\lauetoolsnn\")\n",
    "    from utils_lauenn import get_material_detail, read_hdf5, new_MP_function, global_plots\n",
    "    sys.path.append(r\"C:\\Users\\purushot\\Desktop\\github_version_simple\\lauetoolsnn\\lauetools\")\n",
    "    import dict_LaueTools as dictLT\n",
    "\n",
    "from keras.models import model_from_json\n",
    "import _pickle as cPickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "ncpu = cpu_count()\n",
    "print(\"Number of CPUs available : \", ncpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f1a516-47c8-44fe-9026-c727f4717137",
   "metadata": {},
   "source": [
    "## step 1: define material and path to data and trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bcc574e8-057c-4521-93b4-5df2cbf0c0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "## User Input dictionary with parameters\n",
    "## In case of only one phase/material, keep same value for material_ and material1_ key\n",
    "# =============================================================================\n",
    "input_params = {\n",
    "                \"material_\": \"Cu\",             ## same key as used in dict_LaueTools\n",
    "                \"material1_\": \"Cu\",            ## same key as used in dict_LaueTools\n",
    "                \"prefix\" : \"\",                 ## prefix for the folder to be created for training dataset\n",
    "                \"symmetry\": \"cubic\",           ## crystal symmetry of material_\n",
    "                \"symmetry1\": \"cubic\",          ## crystal symmetry of material1_\n",
    "                \"SG\": 225,                     ## Space group of material_ (None if not known)\n",
    "                \"SG1\": 225,                    ## Space group of material1_ (None if not known)\n",
    "                ## Detector parameters (roughly) of the Experimental setup\n",
    "                ## Sample-detector distance, X center, Y center, two detector angles\n",
    "                \"detectorparameters\" :  [79.553,979.32,932.31,0.37,0.447], \n",
    "                \"pixelsize\" : 0.0734,          ## Detector pixel size\n",
    "                \"dim1\":2018,                   ## Dimensions of detector in pixels\n",
    "                \"dim2\":2016,\n",
    "                \"emin\" : 5,                    ## Minimum and maximum energy to use for simulating Laue Patterns\n",
    "                \"emax\" : 22,\n",
    "                \"experimental_directory\": \"\",\n",
    "                \"experimental_prefix\": \"\",\n",
    "                \"use_simulated_dataset\": True,  ## Use simulated dataset (generated at step 3a) incase no experimental data to verify the trained model\n",
    "                \"grid_size_x\" : 25,            ## Grid X and Y limit to generate the simulated dataset (a rectangular scan region)\n",
    "                \"grid_size_y\" : 25,\n",
    "                }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14aba1f-1354-47a3-993f-5a013674ba9f",
   "metadata": {},
   "source": [
    "## Step 2: Get material parameters \n",
    "### Get model and data paths from the input\n",
    "### User input parameters for various algorithms to compute the orientation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6f8d14a-a6a9-4848-bde2-3de720d7ceac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory where trained model is stored : C:\\Users\\purushot\\Desktop\\github_version_simple\\lauetoolsnn\\example_notebook_scripts//Cu\n",
      "Constructing model\n",
      "Uploading weights to model\n",
      "All model files found and loaded\n"
     ]
    }
   ],
   "source": [
    "material_= input_params[\"material_\"]\n",
    "material1_= input_params[\"material1_\"]\n",
    "detectorparameters = input_params[\"detectorparameters\"]\n",
    "pixelsize = input_params[\"pixelsize\"]\n",
    "emax = input_params[\"emax\"]\n",
    "emin = input_params[\"emin\"]\n",
    "dim1 = input_params[\"dim1\"]\n",
    "dim2 = input_params[\"dim2\"]\n",
    "symm_ = input_params[\"symmetry\"]\n",
    "symm1_ = input_params[\"symmetry1\"]\n",
    "SG = input_params[\"SG\"]\n",
    "SG1 = input_params[\"SG1\"]\n",
    "\n",
    "if material_ != material1_:\n",
    "    model_direc = os.getcwd()+\"//\"+material_+\"_\"+material1_+input_params[\"prefix\"]\n",
    "else:\n",
    "    model_direc = os.getcwd()+\"//\"+material_+input_params[\"prefix\"]\n",
    "    \n",
    "if not os.path.exists(model_direc):\n",
    "    print(\"The directory doesn't exists; please veify the path\")\n",
    "else:\n",
    "    print(\"Directory where trained model is stored : \"+model_direc)\n",
    "\n",
    "if material_ != material1_:\n",
    "    prefix1 = material_+\"_\"+material1_\n",
    "else:\n",
    "    prefix1 = material_\n",
    "\n",
    "if input_params[\"experimental_directory\"] == \"\" and input_params[\"experimental_prefix\"] == \"\":\n",
    "    filenameDirec =  model_direc + \"//simulated_dataset\"\n",
    "    experimental_prefix = prefix1+\"_\"\n",
    "    lim_x, lim_y = input_params[\"grid_size_x\"], input_params[\"grid_size_y\"]\n",
    "    format_file = \"cor\"\n",
    "else:\n",
    "    filenameDirec = input_params[\"experimental_directory\"]\n",
    "    experimental_prefix = input_params[\"experimental_prefix\"]\n",
    "    lim_x, lim_y = input_params[\"grid_size_x\"], input_params[\"grid_size_y\"] \n",
    "    format_file = dictLT.dict_CCD[\"sCMOS\"][7]\n",
    "## Experimental peak search parameters in case of RAW LAUE PATTERNS from detector\n",
    "intensity_threshold = 50\n",
    "boxsize = 10\n",
    "fit_peaks_gaussian = 1\n",
    "FitPixelDev = 18\n",
    "NumberMaxofFits = 2000 ### Max peaks per LP\n",
    "bkg_treatment = \"A-B\"\n",
    "\n",
    "## get unit cell parameters and other details required for simulating Laue patterns\n",
    "rules, symmetry, lattice_material, \\\n",
    "    crystal, SG, rules1, symmetry1,\\\n",
    "    lattice_material1, crystal1, SG1 = get_material_detail(material_, SG, symm_,\n",
    "                                                           material1_, SG1, symm1_)\n",
    "\n",
    "## get proper Laue group to compute the inverse pole figure colors and write MTEX output file for orientation analysis\n",
    "material0_lauegroup = \"11\"\n",
    "## incase of same material\n",
    "material1_lauegroup = material0_lauegroup\n",
    "\n",
    "## Requirements\n",
    "ubmat = 1 # How many orientation matrix to detect per Laue pattern\n",
    "mode_spotCycle = \"graphmode\" ## mode of calculation\n",
    "use_previous_UBmatrix_name = False ## Try previous indexation solutions to speed up the process\n",
    "strain_calculation = True ## Strain refinement is required or not\n",
    "ccd_label_global = \"sCMOS\"\n",
    "\n",
    "## tolerance angle to match simulated and experimental spots for two materials\n",
    "tolerance = 0.6\n",
    "tolerance1 = 0.6\n",
    "\n",
    "## tolerance angle for strain refinements\n",
    "tolerance_strain = [0.6,0.55,0.5,0.45,0.4,0.35,0.3,0.25,0.2,0.15]\n",
    "tolerance_strain1 = [0.6,0.55,0.5,0.45,0.4,0.35,0.3,0.25,0.2,0.15]\n",
    "strain_free_parameters = [\"b\",\"c\",\"alpha\",\"beta\",\"gamma\"]\n",
    "\n",
    "## Parameters to control the orientation matrix indexation\n",
    "softmax_threshold_global = 0.80 # softmax_threshold of the Neural network to consider\n",
    "mr_threshold_global = 0.90 # match rate threshold to accept a solution immediately\n",
    "cap_matchrate = 0.01 * 100 ## any UB matrix providing MR less than this will be ignored\n",
    "coeff = 0.10            ## coefficient to calculate the overlap of two solutions\n",
    "coeff_overlap = 0.10    ##10% spots overlap is allowed with already indexed orientation\n",
    "material0_limit = 100000  ## how many UB can be proposed for first material\n",
    "material1_limit = 100000 ## how many UB can be proposed for second material; this forces the orientation matrix deduction algorithm to find only a required materials matrix\n",
    "material_phase_always_present = \"none\" ## in case if one phase is always present in a Laue pattern (useful for substrate cases)\n",
    "\n",
    "## Additional parameters to refine the orientation matrix construction process\n",
    "use_om_user = False\n",
    "nb_spots_consider = 500\n",
    "residues_threshold=0.5\n",
    "nb_spots_global_threshold=8\n",
    "option_global = \"v2\"\n",
    "\n",
    "## load model related files and generate the model\n",
    "json_file = open(model_direc+\"//model_\"+prefix1+\".json\", 'r')\n",
    "classhkl = np.load(model_direc+\"//MOD_grain_classhkl_angbin.npz\")[\"arr_0\"]\n",
    "angbins = np.load(model_direc+\"//MOD_grain_classhkl_angbin.npz\")[\"arr_1\"]\n",
    "ind_mat = None\n",
    "ind_mat1 = None  \n",
    "load_weights = model_direc + \"//model_\"+prefix1+\".h5\"\n",
    "wb = read_hdf5(load_weights)\n",
    "temp_key = list(wb.keys())\n",
    "\n",
    "# # load json and create model\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(loaded_model_json)\n",
    "print(\"Constructing model\")\n",
    "model.load_weights(load_weights)\n",
    "print(\"Uploading weights to model\")\n",
    "print(\"All model files found and loaded\")\n",
    "\n",
    "hkl_all_class1 = None\n",
    "with open(model_direc+\"//classhkl_data_nonpickled_\"+material_+\".pickle\", \"rb\") as input_file:\n",
    "    hkl_all_class0 = cPickle.load(input_file)[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfab32b5-d977-419f-bb49-36d9a518dd27",
   "metadata": {},
   "source": [
    "## Step 3: Initialize variables and prepare arguments for multiprocessing module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02770b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected 625 files based on the XY grid (25,25) defined by user\n",
      "and found 625 files\n"
     ]
    }
   ],
   "source": [
    "col = [[] for i in range(int(ubmat))]\n",
    "colx = [[] for i in range(int(ubmat))]\n",
    "coly = [[] for i in range(int(ubmat))]\n",
    "rotation_matrix = [[] for i in range(int(ubmat))]\n",
    "strain_matrix = [[] for i in range(int(ubmat))]\n",
    "strain_matrixs = [[] for i in range(int(ubmat))]\n",
    "match_rate = [[] for i in range(int(ubmat))]\n",
    "spots_len = [[] for i in range(int(ubmat))]\n",
    "iR_pix = [[] for i in range(int(ubmat))]\n",
    "fR_pix = [[] for i in range(int(ubmat))]\n",
    "mat_global = [[] for i in range(int(ubmat))]\n",
    "best_match = [[] for i in range(int(ubmat))]\n",
    "spots1_global = [[] for i in range(int(ubmat))]\n",
    "for i in range(int(ubmat)):\n",
    "    col[i].append(np.zeros((lim_x*lim_y,3)))\n",
    "    colx[i].append(np.zeros((lim_x*lim_y,3)))\n",
    "    coly[i].append(np.zeros((lim_x*lim_y,3)))\n",
    "    rotation_matrix[i].append(np.zeros((lim_x*lim_y,3,3)))\n",
    "    strain_matrix[i].append(np.zeros((lim_x*lim_y,3,3)))\n",
    "    strain_matrixs[i].append(np.zeros((lim_x*lim_y,3,3)))\n",
    "    match_rate[i].append(np.zeros((lim_x*lim_y,1)))\n",
    "    spots_len[i].append(np.zeros((lim_x*lim_y,1)))\n",
    "    iR_pix[i].append(np.zeros((lim_x*lim_y,1)))\n",
    "    fR_pix[i].append(np.zeros((lim_x*lim_y,1)))\n",
    "    mat_global[i].append(np.zeros((lim_x*lim_y,1)))\n",
    "    best_match[i].append([[] for jk in range(lim_x*lim_y)])\n",
    "    spots1_global[i].append([[] for jk in range(lim_x*lim_y)])\n",
    "\n",
    "if use_previous_UBmatrix_name:\n",
    "    np.savez_compressed(model_direc+'//rotation_matrix_indexed_1.npz', rotation_matrix, mat_global, match_rate, 0.0)\n",
    "\n",
    "# =============================================================================\n",
    "#         ## Multi-processing routine\n",
    "# =============================================================================        \n",
    "## Number of files to generate\n",
    "grid_files = np.zeros((lim_x,lim_y))\n",
    "filenm = np.chararray((lim_x,lim_y), itemsize=1000)\n",
    "grid_files = grid_files.ravel()\n",
    "filenm = filenm.ravel()\n",
    "count_global = lim_x * lim_y\n",
    "list_of_files = glob.glob(filenameDirec+'//'+experimental_prefix+'*.'+format_file)\n",
    "## sort files\n",
    "## TypeError: '<' not supported between instances of 'str' and 'int'\n",
    "list_of_files.sort(key=lambda var:[int(x) if x.isdigit() else x for x in re.findall(r'[^0-9]|[0-9]+', var)])\n",
    "\n",
    "if len(list_of_files) == count_global:\n",
    "    for ii in range(len(list_of_files)):\n",
    "        grid_files[ii] = ii\n",
    "        filenm[ii] = list_of_files[ii]     \n",
    "    print(\"expected \"+str(count_global)+\" files based on the XY grid (\"+str(lim_x)+\",\"+str(lim_y)+\") defined by user\")\n",
    "    print(\"and found \"+str(len(list_of_files))+\" files\")\n",
    "else:\n",
    "    print(\"expected \"+str(count_global)+\" files based on the XY grid (\"+str(lim_x)+\",\"+str(lim_y)+\") defined by user\")\n",
    "    print(\"But found \"+str(len(list_of_files))+\" files (either all data is not written yet or maybe XY grid definition is not proper)\")\n",
    "    digits = len(str(count_global))\n",
    "    digits = max(digits,4)\n",
    "    # Temp fix\n",
    "    for ii in range(count_global):\n",
    "        text = str(ii)\n",
    "        if ii < 10000:\n",
    "            string = text.zfill(4)\n",
    "        else:\n",
    "            string = text.zfill(5)\n",
    "        file_name_temp = filenameDirec+'//'+experimental_prefix + string+'.'+format_file\n",
    "        ## store it in a grid \n",
    "        filenm[ii] = file_name_temp\n",
    "\n",
    "check = np.zeros((count_global,int(ubmat)))\n",
    "# =============================================================================\n",
    "blacklist = None\n",
    "\n",
    "### Create a COR directory to be loaded in LaueToolsNN\n",
    "cor_file_directory = filenameDirec + \"//\" + experimental_prefix+\"CORfiles\"\n",
    "if format_file in [\"cor\", \"COR\", \"Cor\"]:\n",
    "    cor_file_directory = filenameDirec\n",
    "if not os.path.exists(cor_file_directory):\n",
    "    os.makedirs(cor_file_directory)\n",
    "\n",
    "try_prevs = False\n",
    "files_treated = []\n",
    "\n",
    "valu12 = [[filenm[ii].decode(), ii,\n",
    "           rotation_matrix,\n",
    "            strain_matrix,\n",
    "            strain_matrixs,\n",
    "            col,\n",
    "            colx,\n",
    "            coly,\n",
    "            match_rate,\n",
    "            spots_len, \n",
    "            iR_pix, \n",
    "            fR_pix,\n",
    "            best_match,\n",
    "            mat_global,\n",
    "            check,\n",
    "            detectorparameters,\n",
    "            pixelsize,\n",
    "            angbins,\n",
    "            classhkl,\n",
    "            hkl_all_class0,\n",
    "            hkl_all_class1,\n",
    "            emin,\n",
    "            emax,\n",
    "            material_,\n",
    "            material1_,\n",
    "            symmetry,\n",
    "            symmetry1,   \n",
    "            lim_x,\n",
    "            lim_y,\n",
    "            strain_calculation, \n",
    "            ind_mat, ind_mat1,\n",
    "            model_direc, float(tolerance),\n",
    "            float(tolerance1),\n",
    "            int(ubmat), ccd_label_global, \n",
    "            None,\n",
    "            float(intensity_threshold),\n",
    "            int(boxsize),bkg_treatment,\n",
    "            filenameDirec, \n",
    "            experimental_prefix,\n",
    "            blacklist,\n",
    "            None,\n",
    "            files_treated,\n",
    "            try_prevs, ## try previous is kept true, incase if its stuck in loop\n",
    "            wb,\n",
    "            temp_key,\n",
    "            cor_file_directory,\n",
    "            mode_spotCycle,\n",
    "            softmax_threshold_global,\n",
    "            mr_threshold_global,\n",
    "            cap_matchrate,\n",
    "            tolerance_strain,\n",
    "            tolerance_strain1,\n",
    "            NumberMaxofFits,\n",
    "            fit_peaks_gaussian,\n",
    "            FitPixelDev,\n",
    "            coeff,\n",
    "            coeff_overlap,\n",
    "            material0_limit,\n",
    "            material1_limit,\n",
    "            use_previous_UBmatrix_name,\n",
    "            material_phase_always_present,\n",
    "            crystal,\n",
    "            crystal1,\n",
    "            strain_free_parameters] for ii in range(count_global)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19cc404-f6eb-4a96-97b2-8cfafbeb1af5",
   "metadata": {},
   "source": [
    "## Step 4: Launch multiprocessing prediction and orientation matrix calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201ff31f-8b6c-44ef-be57-1f58a4150a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    pool = multiprocessing.Pool(ncpu)\n",
    "    pbar = tqdm(total=len(valu12))\n",
    "    def update(*a):\n",
    "        pbar.update()\n",
    "    for i in range(pbar.total):\n",
    "        results = pool.apply_async(new_MP_function, args=([valu12[i]]), callback=update)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "    #args = zip(valu12)\n",
    "    #with multiprocessing.Pool(ncpu) as pool:\n",
    "    #    results = pool.starmap(new_MP_function, tqdm(valu12, total=len(valu12)))\n",
    "        \n",
    "    for r in results:\n",
    "        r_message_mpdata = r.get()\n",
    "        strain_matrix_mpdata, strain_matrixs_mpdata, rotation_matrix_mpdata, col_mpdata,\\\n",
    "        colx_mpdata, coly_mpdata, match_rate_mpdata, mat_global_mpdata,\\\n",
    "            cnt_mpdata, meta_mpdata, files_treated_mpdata, spots_len_mpdata, \\\n",
    "                iR_pixel_mpdata, fR_pixel_mpdata, best_match_mpdata, check_mpdata = r_message_mpdata\n",
    "\n",
    "        for i_mpdata in files_treated_mpdata:\n",
    "            files_treated.append(i_mpdata)\n",
    "\n",
    "        for intmat_mpdata in range(int(ubmat)):\n",
    "            check[cnt_mpdata,intmat_mpdata] = check_mpdata[cnt_mpdata,intmat_mpdata]\n",
    "            mat_global[intmat_mpdata][0][cnt_mpdata] = mat_global_mpdata[intmat_mpdata][0][cnt_mpdata]\n",
    "            strain_matrix[intmat_mpdata][0][cnt_mpdata,:,:] = strain_matrix_mpdata[intmat_mpdata][0][cnt_mpdata,:,:]\n",
    "            strain_matrixs[intmat_mpdata][0][cnt_mpdata,:,:] = strain_matrixs_mpdata[intmat_mpdata][0][cnt_mpdata,:,:]\n",
    "            rotation_matrix[intmat_mpdata][0][cnt_mpdata,:,:] = rotation_matrix_mpdata[intmat_mpdata][0][cnt_mpdata,:,:]\n",
    "            col[intmat_mpdata][0][cnt_mpdata,:] = col_mpdata[intmat_mpdata][0][cnt_mpdata,:]\n",
    "            colx[intmat_mpdata][0][cnt_mpdata,:] = colx_mpdata[intmat_mpdata][0][cnt_mpdata,:]\n",
    "            coly[intmat_mpdata][0][cnt_mpdata,:] = coly_mpdata[intmat_mpdata][0][cnt_mpdata,:]\n",
    "            match_rate[intmat_mpdata][0][cnt_mpdata] = match_rate_mpdata[intmat_mpdata][0][cnt_mpdata]\n",
    "            spots_len[intmat_mpdata][0][cnt_mpdata] = spots_len_mpdata[intmat_mpdata][0][cnt_mpdata]\n",
    "            iR_pix[intmat_mpdata][0][cnt_mpdata] = iR_pixel_mpdata[intmat_mpdata][0][cnt_mpdata]\n",
    "            fR_pix[intmat_mpdata][0][cnt_mpdata] = fR_pixel_mpdata[intmat_mpdata][0][cnt_mpdata]\n",
    "            best_match[intmat_mpdata][0][cnt_mpdata] = best_match_mpdata[intmat_mpdata][0][cnt_mpdata]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "863eb00c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [03:05<00:00,  3.37it/s] \n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":    \n",
    "    args = zip(valu12)\n",
    "    with multiprocessing.Pool(ncpu) as pool:\n",
    "        results = pool.starmap(new_MP_function, tqdm(args, total=len(valu12)))\n",
    "        \n",
    "        for r in results:\n",
    "            r_message_mpdata = r\n",
    "            strain_matrix_mpdata, strain_matrixs_mpdata, rotation_matrix_mpdata, col_mpdata,\\\n",
    "            colx_mpdata, coly_mpdata, match_rate_mpdata, mat_global_mpdata,\\\n",
    "                cnt_mpdata, meta_mpdata, files_treated_mpdata, spots_len_mpdata, \\\n",
    "                    iR_pixel_mpdata, fR_pixel_mpdata, best_match_mpdata, check_mpdata = r_message_mpdata\n",
    "    \n",
    "            for i_mpdata in files_treated_mpdata:\n",
    "                files_treated.append(i_mpdata)\n",
    "    \n",
    "            for intmat_mpdata in range(int(ubmat)):\n",
    "                check[cnt_mpdata,intmat_mpdata] = check_mpdata[cnt_mpdata,intmat_mpdata]\n",
    "                mat_global[intmat_mpdata][0][cnt_mpdata] = mat_global_mpdata[intmat_mpdata][0][cnt_mpdata]\n",
    "                strain_matrix[intmat_mpdata][0][cnt_mpdata,:,:] = strain_matrix_mpdata[intmat_mpdata][0][cnt_mpdata,:,:]\n",
    "                strain_matrixs[intmat_mpdata][0][cnt_mpdata,:,:] = strain_matrixs_mpdata[intmat_mpdata][0][cnt_mpdata,:,:]\n",
    "                rotation_matrix[intmat_mpdata][0][cnt_mpdata,:,:] = rotation_matrix_mpdata[intmat_mpdata][0][cnt_mpdata,:,:]\n",
    "                col[intmat_mpdata][0][cnt_mpdata,:] = col_mpdata[intmat_mpdata][0][cnt_mpdata,:]\n",
    "                colx[intmat_mpdata][0][cnt_mpdata,:] = colx_mpdata[intmat_mpdata][0][cnt_mpdata,:]\n",
    "                coly[intmat_mpdata][0][cnt_mpdata,:] = coly_mpdata[intmat_mpdata][0][cnt_mpdata,:]\n",
    "                match_rate[intmat_mpdata][0][cnt_mpdata] = match_rate_mpdata[intmat_mpdata][0][cnt_mpdata]\n",
    "                spots_len[intmat_mpdata][0][cnt_mpdata] = spots_len_mpdata[intmat_mpdata][0][cnt_mpdata]\n",
    "                iR_pix[intmat_mpdata][0][cnt_mpdata] = iR_pixel_mpdata[intmat_mpdata][0][cnt_mpdata]\n",
    "                fR_pix[intmat_mpdata][0][cnt_mpdata] = fR_pixel_mpdata[intmat_mpdata][0][cnt_mpdata]\n",
    "                best_match[intmat_mpdata][0][cnt_mpdata] = best_match_mpdata[intmat_mpdata][0][cnt_mpdata]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ca33f3-fd03-4e96-bbd4-79fb4fee2766",
   "metadata": {},
   "source": [
    "## Verify the results with Ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4d6b3a47-7a92-4deb-a1cc-79c58873ee57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth OM is \n",
      " [[ 0.39502  0.46967  0.78954]\n",
      " [-0.81632 -0.21477  0.53618]\n",
      " [ 0.4214  -0.85632  0.29856]]\n",
      "Neural network indexed matrix \n",
      " [[-0.78954 -0.39502  0.46967]\n",
      " [-0.53618  0.81632 -0.21477]\n",
      " [-0.29856 -0.4214  -0.85632]]\n"
     ]
    }
   ],
   "source": [
    "## Load the ground truth, we know the orientation matrix, since the data is simulated one\n",
    "groundtruth_OM = np.load(filenameDirec+\"//groundtruth_OM.npz\")[\"arr_0\"]\n",
    "\n",
    "print(\"Ground Truth OM is \\n\", np.round(groundtruth_OM[0,0,:,:],5))\n",
    "print(\"Neural network indexed matrix \\n\", np.round(rotation_matrix[0][0][0,:,:],5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7444ce63-d901-4922-a1a8-17ef3e8e957f",
   "metadata": {},
   "source": [
    "## Step 5: Save results data to a pickle file and use lauetoolsNN GUI to visualize results and save them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "92bf559f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data saved in  C:\\Users\\purushot\\Desktop\\github_version_simple\\lauetoolsnn\\example_notebook_scripts//Cu//simulated_dataset//results_Cu_2022-03-30_10-50-43\n"
     ]
    }
   ],
   "source": [
    "curr_time = time.time()\n",
    "now = datetime.datetime.fromtimestamp(curr_time)\n",
    "c_time = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "save_directory_ = filenameDirec+\"//results_\"+material_+\"_\"+c_time\n",
    "if not os.path.exists(save_directory_):\n",
    "    os.makedirs(save_directory_)\n",
    "    \n",
    "## intermediate saving of pickle objects with results\n",
    "with open(save_directory_+ \"//results.pickle\", \"wb\") as output_file:\n",
    "        cPickle.dump([best_match, mat_global, rotation_matrix, strain_matrix, \n",
    "                      strain_matrixs, col, colx, coly, match_rate, files_treated,\n",
    "                      lim_x, lim_y, spots_len, iR_pix, fR_pix,\n",
    "                      material_, material1_, lattice_material, lattice_material1,\n",
    "                      symmetry, symmetry1, crystal, crystal1], output_file)\n",
    "print(\"data saved in \", save_directory_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b5e689",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee22d1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a43ff5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c736ead",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33a2c94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
